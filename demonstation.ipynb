{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "train_set, valid_set = torch.utils.data.random_split(train_dataset, [40000, 10000])\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True, num_workers=2)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=False, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, epochs=10, device='cpu', model_name='model'):\n",
    "    model.to(device)\n",
    "\n",
    "    train_loss_history = []\n",
    "    train_accuracy_history = []\n",
    "    \n",
    "    valid_loss_history = []\n",
    "    valid_accuracy_history = []\n",
    "    \n",
    "    best_iter = 0\n",
    "    best_valid_loss = float('inf')\n",
    "    best_valid_accuracy = 0.0\n",
    "    best_model = None\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        train_loss, train_corrects = 0.0, 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            predicted = outputs.argmax(dim=1)\n",
    "            train_corrects += (predicted == labels).sum().item()\n",
    "    \n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_accuracy = train_corrects / len(train_loader.dataset)\n",
    "\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_accuracy_history.append(train_accuracy)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        valid_loss, valid_corrects = 0.0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(valid_loader, desc=f'Epoch {epoch+1}/{epochs}'):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                predicted = outputs.argmax(dim=1)\n",
    "                valid_corrects += (predicted == labels).sum().item()\n",
    "        \n",
    "        valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "        valid_accuracy = valid_corrects / len(valid_loader.dataset)\n",
    "        \n",
    "        if valid_accuracy > best_valid_accuracy:\n",
    "            best_iter = epoch + 1\n",
    "            best_valid_loss = valid_loss\n",
    "            best_valid_accuracy = valid_accuracy\n",
    "            best_model = model.state_dict()\n",
    "        \n",
    "        valid_loss_history.append(valid_loss)\n",
    "        valid_accuracy_history.append(valid_accuracy)\n",
    "        \n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "        print(f'Valid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.4f}')\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f'Total training time: {end_time - start_time:.2f} seconds.')\n",
    "    \n",
    "    torch.save(best_model, f'weights/{model_name}_best.pth')\n",
    "    \n",
    "    print(f'Best model at epoch {best_iter} with valid loss: {best_valid_loss:.4f}, valid accuracy: {best_valid_accuracy:.4f}')\n",
    "\n",
    "    return train_loss_history, train_accuracy_history, valid_loss_history, valid_accuracy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss, test_corrects = 0.0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            predicted = outputs.argmax(dim=1)\n",
    "            test_corrects += (predicted == labels).sum().item()\n",
    "        \n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    test_accuracy = test_corrects / len(test_loader.dataset)\n",
    "    \n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}%')\n",
    "    \n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import lnn, cnn\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnn_model = lnn.LNN(32 * 32 * 3, num_classes=10)\n",
    "\n",
    "num_params = sum([p.numel() for p in lnn_model.parameters()])\n",
    "print(\"Number of parameters: \", num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lnn_model.parameters(), lr=0.001)\n",
    "\n",
    "train_loss_history, train_accuracy_history, valid_loss_history, valid_accuracy_history = train_model(lnn_model, train_loader, valid_loader, criterion, optimizer, epochs=50, device='cuda', model_name='lnn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(range(1, len(train_loss_history) + 1), train_loss_history, label='Training Loss', linewidth=3)\n",
    "plt.plot(range(1, len(valid_loss_history) + 1), valid_loss_history, label='Validation Loss', linewidth=3)\n",
    "\n",
    "plt.title('Training & Validation Loss History', fontsize=20)\n",
    "plt.xlabel('Epoch', fontsize=18)\n",
    "plt.ylabel('Loss', fontsize=18)\n",
    "plt.legend(loc='lower left', fontsize=15)\n",
    "\n",
    "plt.savefig('figures/lnn_loss_history.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(range(1, len(train_accuracy_history) + 1), train_accuracy_history, label='Training Accuracy', linewidth=3)\n",
    "plt.plot(range(1, len(valid_accuracy_history) + 1), valid_accuracy_history, label='Validation Accuracy', linewidth=3)\n",
    "\n",
    "plt.title('Training & Validation Accuracy History', fontsize=20)\n",
    "plt.xlabel('Epoch', fontsize=18)\n",
    "plt.ylabel('Loss', fontsize=18)\n",
    "plt.legend(loc='upper left', fontsize=15)\n",
    "\n",
    "plt.savefig('figures/lnn_accuracy_history.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = test_model(lnn_model, test_loader, criterion, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = cnn.CNN(3, num_classes=10)\n",
    "\n",
    "num_params = sum([p.numel() for p in cnn_model.parameters()])\n",
    "print(\"Number of parameters: \", num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "train_loss_history, train_accuracy_history, valid_loss_history, valid_accuracy_history = train_model(cnn_model, train_loader, valid_loader, criterion, optimizer, epochs=30, device='cuda', model_name='cnn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(range(1, len(train_loss_history) + 1), train_loss_history, label='Training Loss', linewidth=3)\n",
    "plt.plot(range(1, len(valid_loss_history) + 1), valid_loss_history, label='Validation Loss', linewidth=3)\n",
    "\n",
    "plt.title('Training & Validation Loss History', fontsize=20)\n",
    "plt.xlabel('Epoch', fontsize=18)\n",
    "plt.ylabel('Loss', fontsize=18)\n",
    "plt.legend(loc='lower left', fontsize=15)\n",
    "\n",
    "plt.savefig('figures/cnn_loss_history.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(range(1, len(train_accuracy_history) + 1), train_accuracy_history, label='Training Accuracy', linewidth=3)\n",
    "plt.plot(range(1, len(valid_accuracy_history) + 1), valid_accuracy_history, label='Validation Accuracy', linewidth=3)\n",
    "\n",
    "plt.title('Training & Validation Accuracy History', fontsize=20)\n",
    "plt.xlabel('Epoch', fontsize=18)\n",
    "plt.ylabel('Loss', fontsize=18)\n",
    "plt.legend(loc='upper left', fontsize=15)\n",
    "\n",
    "plt.savefig('figures/cnn_accuracy_history.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = test_model(cnn_model, test_loader, criterion, device='cuda')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
